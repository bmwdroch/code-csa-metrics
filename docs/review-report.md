# Отчёт о проверке прототипа CSA Metrics

## 1. Вводные

Проверка выполнена на двенадцати прогонах, охватывающих два репозитория, два режима работы, негативные сценарии, верификацию реализованных рекомендаций и проверку нормализации метрик:

| Прогон | Репозиторий | Режим | Maven-кеш | Цель |
|--------|-------------|-------|-----------|------|
| 1 | langchain4j (2449 .java) | full | холодный | Крупная библиотека, нагрузочный тест |
| 2 | langchain4j | fast | — | Тот же проект без разрешения зависимостей |
| 3 | spring-petclinic (47 .java) | full | холодный | Веб-приложение с контроллерами |
| 4 | spring-petclinic | fast | — | Тот же проект без разрешения зависимостей |
| 5 | spring-petclinic | full | прогретый | Оценка эффекта кеширования |
| 6 | несуществующий репозиторий | fast | — | Обработка ошибок сети |
| 7 | spring-petclinic | full v2 | холодный | Верификация multi-stage образа с JRE |
| 8 | spring-petclinic | full | — | Верификация timeout (5 с) |
| 9 | spring-petclinic | fast v2 | — | Верификация нормализации и агрегата |
| 10 | langchain4j | fast v2 | — | Верификация нормализации (библиотека) |
| 11 | spring-petclinic | fast v3 | — | Финальная верификация после удаления фолбэка |
| 12 | langchain4j | fast v3 | — | Финальная верификация (библиотека без входных точек) |

Spring Petclinic выбран намеренно: это веб-приложение Spring Boot с HTTP-контроллерами, валидацией форм, JPA-репозиториями и без настроенной авторизации, что позволяет проверить работу метрик групп A, B и C на реальных входных точках. Langchain4j выбран как представитель крупных библиотек без собственного веб-слоя -- для таких проектов метрики, зависящие от сетевых точек входа, корректно обнуляются.


---

## 2. Сводка производительности

### 2.1 Ключевое наблюдение: одна метрика определяет 93-98% времени

Разница между режимами fast и full составляет порядок величины, и целиком объясняется единственной метрикой E1 (OSDR), которая запускает `mvnw dependency:list` для разрешения транзитивных Maven-зависимостей. Остальные 14 метрик работают на чистом парсинге исходников через tree-sitter и не требуют ни сети, ни JVM.

```
                    langchain4j                 spring-petclinic
                    full (cold)     fast        full (cold)     fast
                    ───────────     ────        ───────────     ────
Wall clock          236.0 с         15.0 с      44.4 с          1.7 с
  git clone           2.5 с         2.6 с       1.3 с          0.9 с
  mvnw deps (E1)    221.7 с         —           42.1 с          —
  граф + метрики      10.7 с        11.3 с       0.1 с          0.2 с
Множитель           ×15.7                       ×25.5
```

Иными словами: в fast mode petclinic анализируется за ~1.7 с, langchain4j за ~15 с. Полный анализ тех же проектов занимает ~44 и ~236 с соответственно, причём прирост времени обеспечен исключительно скачиванием и разрешением Maven-артефактов для одной метрики из пятнадцати.

### 2.2 Потребление ресурсов

```
                    langchain4j                 spring-petclinic
                    full (cold)     fast        full (cold)     fast
                    ───────────     ────        ───────────     ────
CPU пик (%)         349             113         242             45
Память пик (МБ)     425             116         196             27
```

Картина аналогична временным замерам. В fast mode langchain4j потребляет ~1 ядро и 116 МБ (Python tree-sitter удерживает граф из 18360 узлов). В full mode добавляется JVM Maven, поднимающая пик CPU до ~3.5 ядер и память до ~425 МБ. Для petclinic в fast mode нагрузка остаётся небольшой (порядка 0.2 с на метрики), а docker stats уже успевает зафиксировать пик CPU (~45%).

### 2.3 Масштабируемость построения графа

Время построения графа вызовов через tree-sitter линейно зависит от количества Java-файлов:

```
Файлов      Узлов       Рёбер       Время
──────      ─────       ─────       ─────
47          163         257         0.15 с
2449        18360       589051      9.93 с
```

### 2.4 Размеры артефактов

```
Docker-образы (multi-stage):
  csa-metrics:fast        305 МБ  (python:3.12-slim + tree-sitter, без JVM)
  csa-metrics:full        517 МБ  (+ JRE headless для Maven)
Кеш Maven (cold):        1.9 ГБ (только при full mode)

Выходные файлы:
  langchain4j combined:   5.1 МБ 
  petclinic combined:     104 КБ
```

После перехода на multi-stage сборку размер fast-образа сократился с 612 до 305 МБ за счёт исключения JRE. Full-образ использует JRE вместо полного JDK и занимает 517 МБ. Оркестратор автоматически выбирает образ по режиму: `csa-metrics:fast` или `csa-metrics:full`.

---

## 3. Валидация метрик безопасности

### 3.1 Сравнительная таблица

Все метрики приведены к единой шкале [0, 1], где 0 означает безопасно, а 1 -- критично. Исходные (ненормализованные) значения сохранены в полях `raw_*` соответствующих метрик. Значения получены в fast mode. Входные точки определяются исключительно по сетевым аннотациям (`@RequestMapping`, `@KafkaListener` и аналогичные); для библиотек без веб-слоя метрики, зависящие от точек входа, обнуляются.

```
Метрика      langchain4j          spring-petclinic     Комментарий
──────       ───────────          ────────────────     ───────────
A1 ASE       0.000 (raw 0.0)     0.487 (raw 28.0)     Нет сетевых аннотаций → ASE=0
A2 ECI_avg   0.000 (raw max 0.0) 0.017 (raw max 5.0)  Нет entrypoints → нет достижимости
A3 IET       0.000               0.218                Нет entrypoints → IET=0
B1 IDS       1.000 (raw 0.0)     0.833 (raw 0.167)    Инверсия: 0 слоёв хуже 1 слоя
B2 PPI       0.000               1.000 (distance=0)   Нет unauth entrypoints → PPI=0
B3 MPSP      0.000 (raw 0.0)     0.000 (raw 1.0)      Нет путей → нет расхождений
B4 FSS       0.443 (raw 0.557)   0.000 (raw 1.0)      Инверсия: 0 catch = нет данных = 0
C1 TPC       0.000 (raw 0)       0.100 (raw 1)        Нет entrypoints → нет путей
C2 ETI       0.017               0.000                13/758 catch с утечкой
C3 SFA       0.000               0.000                Нет паттернов секрет → лог
D1 PAD       0.500 (raw 2.0)     0.000 (raw 0.0)      cap=4; java+kt+js = 2 границы
D2 TCPD      0.000 (raw 0)       0.000 (raw 0)        cap=10; нет auth-аннотаций
E1 OSDR      n/a (fast)          n/a (fast)           Требуется full mode
F1 VFCP      0.289               0.078                Выше coupling у langchain4j
F2 SRP       0.076               0.000                12 из 158 конструкций без тестов
M1           18360/589051        163/257              Топология, не нормализуется
─────────────────────────────────────────────────────────────────────────────────
AGGREGATE    0.172               0.267                Взвешенный скор [0,1]
```

### 3.2 Нормализация и агрегированный скор

Пять метрик возвращали неограниченные значения, что делало невозможным их прямое сравнение и агрегирование. Для каждой из них введена функция нормализации, подобранная в соответствии с характером распределения.

Для A1 (ASE) выбрана логарифмическая шкала `min(1, log2(1+v) / log2(1+1000))`. Обоснование: разница между ASE=10 и ASE=100 существенна для безопасности (десятикратный рост поверхности атаки), тогда как разница между ASE=5000 и ASE=8000 практически не меняет профиль риска -- проект уже имеет обширный публичный интерфейс. Логарифм естественным образом отражает это затухание. Порог насыщения (cap=1000) выбран так, чтобы типичные веб-приложения (десятки-сотни эндпоинтов) располагались в информативной зоне шкалы.

Для A2 (ECI) агрегирование выполнено через среднее арифметическое top-50 методов с линейным cap при 30. Порог 30 соответствует методу с когнитивной сложностью 30, находящемуся непосредственно в точке входа (distance=0), что является предельным случаем для типичного Java-кода.

Для C1 (TPC), D1 (PAD) и D2 (TCPD) использован линейный cap: `min(1, v/cap)`. Пороги (10, 4 и 10 соответственно) подобраны эмпирически: 10 последовательных хопов без очистки данных, 4 технологических границы и 10 хопов после последней проверки авторизации -- разумные верхние границы, за которыми дальнейший рост значения не меняет качественную оценку риска.

Три метрики (B1, B3, B4) уже возвращали значения в [0, 1], но с обратной семантикой (1 означало безопасно). Для единообразия выполнена инверсия: `1 - v`. Исходные значения сохранены в `raw_IDS`, `raw_MPSP` и `raw_FSS`.

Агрегированный скор вычисляется как взвешенное среднее по всем доступным метрикам (кроме M1, которая несёт топологическую информацию и нормализации не подлежит). Веса распределены по группам: защита в глубину (B1=0.10, B2=0.10) взвешена наиболее высоко, поскольку отсутствие защитных эшелонов является сильнейшим предиктором инцидентов. Поверхность атаки (A1=0.08, A2=0.07, A3=0.07), потоки данных (C1=0.08, C3=0.08, C2=0.06) и архитектура (D2=0.06, D1=0.04) идут следующими. Предсказательные метрики (F1=0.05, F2=0.05) и зависимости (E1=0.06) получили наименьшие веса, поскольку основаны на косвенных сигналах. Сумма весов равна 1.0. Если метрика недоступна (status != "ok" или значение = None), она исключается из расчёта, а веса перенормируются на оставшиеся.

### 3.3 Содержательный анализ

Агрегированный скор разделяет два проекта: spring-petclinic получил 0.267 (умеренный риск), langchain4j -- 0.172 (низкий риск). Соотношение ожидаемо: petclinic является веб-приложением с 17 HTTP-эндпоинтами без авторизации, что создаёт значительную поверхность атаки с прямым доступом к привилегированным операциям (B2=1.0, B1=0.83, A1=0.49). Langchain4j, напротив, не имеет сетевых точек входа, поэтому метрики групп A, B2 и C1 обнуляются. Для библиотеки остаются только структурные характеристики: B1=1.0 (ни одного защитного эшелона на внутренних путях), B4=0.44 (44% catch-блоков не fail-closed), D1=0.5 (три языка в проекте) и VFCP=0.29 (сложность исправления).

Такое поведение отражает осознанное проектное решение: метрики безопасности прототипа ориентированы на анализ развёрнутых приложений с сетевыми интерфейсами, а не библиотек. Библиотека не имеет собственных точек входа и не управляет авторизацией; риски её использования проявляются на уровне приложения-потребителя. Тем не менее структурные метрики (B4, D1, F1, F2, C2) дают полезную информацию о качестве кода библиотеки.

Метрика B2 (PPI=1.0) для petclinic справедливо показала, что неаутентифицированный пользователь имеет прямой доступ (distance=0) к привилегированным операциям: контроллеры вызывают `save`, `persist`, `update` через JPA без единой проверки авторизации. Это соответствует действительности, поскольку spring-petclinic не настраивает Spring Security.

Метрика B1 после инверсии стала более читаемой: langchain4j получил IDS=1.0 (ни одного защитного эшелона на внутренних путях), petclinic -- IDS=0.83 (один эшелон из шести: валидация через `@Valid`). Направление шкалы теперь совпадает с остальными метриками, что упрощает визуальную интерпретацию.

Метрика A1 (ASE) для petclinic после логарифмической нормализации показала 0.487: 17 HTTP-эндпоинтов без auth -- это значимая, но не предельная поверхность атаки. Для langchain4j ASE=0, поскольку в проекте нет сетевых аннотаций (`@RequestMapping`, `@KafkaListener` и т.д.).

Метрика E1 (OSDR) исключена из агрегата в обоих прогонах (fast mode), что приводит к перенормировке весов. В full mode она добавилась со значением 0.848 для petclinic, увеличив итоговый скор с 0.267 до 0.302.

---

## 4. Обнаруженные и исправленные дефекты

В ходе проверки обнаружено четыре дефекта. Все исправлены.

### 4.1 Неверный путь к Dockerfile -- исправлен

Файл `src/orchestrate.py`, строка 177. Путь был указан как `repo_root / "prototype" / "docker" / "Dockerfile"`, фактическое расположение: `src/docker/Dockerfile`. Флаг `--build-image` не работал.

Исправление: заменён путь на `repo_root / "src" / "docker" / "Dockerfile"`.

### 4.2 Оркестратор не пробрасывает exit code контейнера -- исправлен

Файл `src/orchestrate.py`, функция `main()`. Оркестратор записывал `exit_code` контейнера в JSON, но всегда возвращал 0, если не было ошибок на уровне самого оркестратора. Тест с несуществующим репозиторием подтвердил: контейнер завершался с кодом 1, но `orchestrate.py` возвращал 0. В конвейере такое поведение маскирует сбой анализа.

Исправление: добавлена проверка `container_exit != "0"` с возвратом кода 4. Верифицировано на негативном тесте.

### 4.3 Не извлекались типы параметров из tree-sitter AST -- исправлен

Файл `src/analyzer/java_graph.py`, функция `_extract_param_types()`. Функция искала дочерний узел с типом `"type"` через `_first_child(param, "type")`, но tree-sitter для Java использует конкретные типы узлов: `type_identifier` (для `String`, `Owner`), `generic_type` (для `Map<String,Object>`), `integral_type` (для `int`), `array_type` (для `byte[]`). Узла с типом `"type"` не существует.

В результате список типов параметров всегда был пуст, `_param_risk()` всегда возвращала `("low", "low")`, и метрики A1 (ASE) и A3 (IET) систематически занижали риски, не обнаруживая нетипизированные параметры `String`, `Object`, `Map`.

Исправление: заменено на `param.child_by_field_name("type")`, которое корректно извлекает узел типа через именованное поле AST. Верифицировано: после исправления сигнатуры методов содержат типы параметров (`processUpdateForm(RedirectAttributes,BindingResult,Pet,Owner)` вместо `processUpdateForm()`), ASE изменился с 27.16 на 28.0, IET с 0.182 на 0.218.

### 4.4 Regex ETI_LEAK_PAT с двойным экранированием -- исправлен

Файл `src/analyzer/java_graph.py`, строка 40. Паттерн `r"(getMessage\\(\\)|printStackTrace\\(\\))"` содержал двойное экранирование: в сыром литерале `\\(` превращается в регулярное выражение `\(`, которое ищет литеральный символ `(`. Но в Java-коде `getMessage()` пишется как `getMessage()`, а не `getMessage\(\)`. Паттерн никогда не срабатывал, и метрика C2 (ETI) всегда возвращала 0.

Исправление: заменено на `r"(getMessage\(\)|printStackTrace\(\))"`.

---

## 5. Сетевые взаимодействия

Прототип выполняет сетевые вызовы в двух точках.

Первая: `git clone --depth 1` внутри контейнера. Клонирование с глубиной 1 минимизирует трафик (для langchain4j порядка 30 МБ, для petclinic порядка 1.4 МБ). При сбое сети ошибка корректно перехватывается и записывается в `report.json["errors"]`, контейнер завершается с кодом 1, после исправления дефекта 4.2 оркестратор возвращает код 4.

Вторая: `mvnw dependency:list` внутри контейнера, только в full mode. Maven скачивает артефакты из Maven Central. При холодном старте трафик значительный (порядка 1.9 ГБ для petclinic). При монтировании кеша через `-v m2-cache:/root/.m2` сетевой трафик минимален. Если Maven Central недоступен, `mvnw` завершается с ненулевым кодом, ошибка записывается в `tech.deps.mvn_dependency_list_stderr_tail`.

В fast mode единственное сетевое взаимодействие -- `git clone`. Docker-образ собирается на хост-машине и не имеет сетевых зависимостей во время `docker run`.

---

## 6. Архитектурная оценка

### 6.1 Выбор tree-sitter

Решение использовать tree-sitter для парсинга Java обоснованно: он работает на сырых исходниках без сборки проекта, предсказуем по времени выполнения и не требует JDK для парсинга. Для прототипа это разумный компромисс между точностью и скоростью. Ограничение: отсутствие разрешения типов приводит к перепредставлению графа вызовов. Один метод `save()` может связаться с двадцатью методами с таким же именем в разных классах (лимит 20 кандидатов на вызов). Для задачи обнаружения «горячих точек» безопасности приблизительный граф допустим, но точность отдельных метрик (B1, B2, C1) от этого страдает.

### 6.2 Архитектурный диссонанс: E1 vs остальные метрики

14 из 15 метрик полностью автономны: они работают на парсинге исходников, не требуют сети, JVM или внешних инструментов. Метрика E1 (OSDR) нарушает эту модель, запуская полноценный Maven-процесс с разрешением зависимостей. Это создаёт архитектурный диссонанс: одна метрика определяет профиль нагрузки всей системы, потребление ресурсов, сетевые требования и временные ограничения. Вынос E1 в отдельный этап конвейера (или переход на парсинг существующего `dependency:tree` артефакта из предыдущего шага сборки) устранил бы это рассогласование.

### 6.3 Docker-образ

Исходный размер 612 МБ был обусловлен включением JDK headless (порядка 300 МБ) в единственный образ. После реализации рекомендаций 8.4 и 8.7 Dockerfile переведён на multi-stage сборку с тремя стадиями: `base` (Python + tree-sitter + git), `fast` (без JVM, 305 МБ) и `full` (+ JRE headless, 517 МБ). Оркестратор автоматически выбирает образ по режиму (`csa-metrics:fast` или `csa-metrics:full`), а при сборке через `--build-image` использует `docker build --target <mode>`. Таким образом fast-образ сократился вдвое, а full-образ использует JRE вместо полного JDK. Контейнер корректно очищается после завершения (`docker rm -f`); остаточных контейнеров при проверке не обнаружено.

### 6.4 Нормализация и агрегирование

Введение нормализации и агрегированного скора решает практическую задачу: до этого изменения потребитель отчёта вынужден был самостоятельно интерпретировать разнородные значения (ASE=28 vs IET=0.218 vs TPC=1 хоп vs PAD=2 границы). Теперь все метрики выражены на единой шкале, а агрегат предоставляет однозначный индикатор для порогов в конвейере (например, блокировка релиза при score > 0.7).

Нормализация реализована на уровне `metrics.py` в отдельной фазе после вычисления всех метрик. Граф и индивидуальные функции метрик не затронуты, что сохраняет модульность: если потребуется изменить пороги или формулу нормализации, достаточно редактировать константы `_ASE_CAP`, `_ECI_CAP`, `_TPC_CAP`, `_PAD_CAP`, `_TCPD_CAP` и словарь `_METRIC_WEIGHTS`.

Архитектурное решение хранить исходные значения рядом с нормализованными (через `raw_*` поля) позволяет при необходимости пересчитать нормализацию постфактум, не запуская повторный анализ.

### 6.5 Область применения: приложения vs библиотеки

Прототип ориентирован на анализ развёрнутых приложений с сетевыми интерфейсами. Входные точки определяются исключительно по аннотациям вроде `@RequestMapping`, `@KafkaListener`, `@Scheduled`. Для библиотек без веб-слоя (langchain4j) метрики групп A (поверхность атаки), B2 (близость к привилегиям) и C1 (пути заражённых данных) обнуляются, поскольку в проекте отсутствуют сетевые точки входа.

Это осознанное ограничение: безопасность библиотеки проявляется не в собственных входных точках, а в контексте приложения-потребителя. Попытка использовать публичные методы Java как точки входа давала формально большие значения ASE (порядка 8000 для langchain4j), но не несла практического смысла, поскольку публичный метод библиотеки -- это не поверхность атаки в том же смысле, что HTTP-эндпоинт.

Для библиотек остаются информативными структурные метрики: B1 (защитные эшелоны на внутренних путях), B4 (поведение catch-блоков), D1 (технологические границы), F1 (сложность исправления), F2 (покрытие конструкций безопасности тестами) и C2 (утечка через ошибки).

---

## 7. Оценка влияния на конвейер

### 7.1 Временные затраты

```
                    langchain4j                 spring-petclinic
                    full (cold)     fast        full (cold)     fast
                    ───────────     ────        ───────────     ────
Wall clock          236.0 с         15.0 с      44.4 с          1.7 с
Множитель vs fast   ×15.7           ×1          ×25.5           ×1
```

В fast mode анализ занимает от ~1.7 до ~15 с в зависимости от размера проекта. Для сравнения: типичный запуск SonarQube на проекте аналогичного размера занимает 30-120 с. Прототип в fast mode в десятки раз легче SonarQube и допускает запуск на каждый коммит.

В full mode при холодном кеше анализ занимает от ~44 до ~236 с; при прогретом кеше (на примере petclinic) падает до ~5 с. Прирост относительно fast целиком обусловлен разрешением Maven-зависимостей для одной метрики E1. Запуск full mode на каждый коммит нецелесообразен.

Добавление нормализации и агрегирования не повлияло на производительность: вычисления сводятся к десятку арифметических операций над уже готовыми значениями.

### 7.2 Ресурсы

```
                    fast mode       full mode (cold)
                    ─────────       ────────────────
CPU пик             1 ядро          3.5 ядра
Память пик          27-116 МБ       196-425 МБ
Сетевой трафик      git clone       git clone + Maven Central
Диск (кеш)          0               1.9 ГБ (Maven)
```

В fast mode прототип укладывается в ресурсы минимального раннера (1 ядро, 256 МБ, образ 305 МБ). В full mode требуется раннер с 4 ядрами и 2 ГБ памяти (образ 517 МБ). Параметр `--timeout` позволяет ограничить время работы контейнера и предотвратить зависание в конвейере.

### 7.3 Использование агрегированного скора в конвейере

Агрегированный скор предназначен для двух сценариев. Первый -- пороговая проверка: конвейер может блокировать релиз, если `aggregate.score` превышает заданное значение (например, 0.7). Второй -- мониторинг тренда: отслеживание динамики скора между версиями позволяет обнаружить постепенную деградацию безопасности, даже если ни одна метрика не превышает порога по отдельности.

Поле `aggregate.components` позволяет декомпозировать скор и определить, какие именно метрики внесли наибольший вклад. Поле `aggregate.available` показывает, сколько метрик участвовало в расчёте, что важно для оценки полноты: если в fast mode доступно 14 из 15 метрик, скор достаточно представителен; если доступно менее 10, результат следует интерпретировать с осторожностью.
