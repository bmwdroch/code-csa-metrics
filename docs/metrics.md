## Группа A: Поверхность атаки и входные точки

> Что видит атакующий снаружи?

---

### A1. Открытость поверхности атаки (ASE)

Количество входных точек x риски по каждой.

Алгоритм:
- Подсчёт входных точек: `@RequestMapping`, `@KafkaListener`, `@Consumer`, публичные REST-маршруты API.
- Повышающие веса:
  - Метод принимает `String`, `Map`, `Object` (нетипизированные данные - риск инъекций).
  - Нет аннотаций авторизации (`@PreAuthorize`, `@Secured`).
  - Нет явной валидации входных параметров.
- `ASE = Σ(base_weight × risk_multipliers)` по всем точкам входа.

Нормализация: `min(1, log2(1 + ASE) / log2(1 + 1000))`. Логарифмическая шкала выбрана потому, что разница между 10 и 100 точками входа существенна, тогда как разница между 5000 и 8000 практически не меняет профиль риска. Исходное значение сохраняется в `raw_ASE`.

Реализация: `src/analyzer/metrics.py` (`metric_A1_ASE`), нормализация в `_normalize_metrics`. Входные точки определяются только по сетевым аннотациям (`@RequestMapping`, `@GetMapping`, `@PostMapping`, `@KafkaListener` и аналогичные). Проекты без сетевых аннотаций (библиотеки) получают ASE = 0.

---

### A2. Индекс взрывной сложности (ECI)

Сложность кода, умноженная на близость к внешнему входу. Метод со сложностью 20 глубоко внутри - плохо. Метод со сложностью 20, принимающий HTTP Request - критично.

Алгоритм:
- Строим граф вызовов.
- Помечаем точки входа (API, очереди, слушатели).
- Для каждого метода: `ECI = Cognitive_Complexity / (Distance_to_Entry + 1)`.

Нормализация: возвращается top-50 методов с наивысшим ECI. Агрегированное значение `ECI_avg = min(1, avg(top-50) / 30)`, исходный максимум сохраняется в `raw_ECI_max`.

Реализация: `src/analyzer/metrics.py` (`metric_A2_ECI`), нормализация в `_normalize_metrics`.

---

### A3. Входная энтропия (IET)

Количественная мера того, насколько доверчив код к внешним данным. Метод, принимающий `Object`, допускает бесконечное множество входов. Метод с `@Valid CreateUserRequest` - конечное, контролируемое.

Алгоритм:
- Для каждого публичного метода, принимающего внешние данные:
  - Классификация типов параметров:
    - `String`, `Object`, `Map<String,Object>`, `JsonNode` → высокая энтропия
    - `byte[]`, `InputStream` → очень высокая (бинарные данные без структуры)
    - DTO с `@NotNull`, `@Size`, `@Pattern` → низкая энтропия
    - Enum, boolean, bounded int → минимальная
  - Наличие валидации в теле метода снижает результирующую энтропию.
- `IET_system = weighted_avg(IET по точкам входа)`, вес = степень открытости (http > mq > job).

Диапазон: [0, 1], 0 = безопасно. Нормализация не требуется.

Реализация: `src/analyzer/metrics.py` (`metric_A3_IET`).

---

## Группа B: Глубина обороны

> Сколько стен нужно пробить атакующему?

---

### B1. Глубина эшелонированной защиты (IDS)

Количественная оценка принципа Defense-in-Depth - сколько независимых слоёв защиты стоит на каждом критическом пути от входа до чувствительной операции. Система сильна настолько, насколько силён слабейший путь.

Алгоритм:
- Граф вызовов от каждой точки входа до каждого приёмника (БД, ФС, внешний API, ответ клиенту).
- На каждом пути классифицируем защитные слои:
  - Аутентификация (Spring Security filter, проверка токена)
  - Авторизация (`@PreAuthorize`, `hasRole`, проверка принадлежности ресурса)
  - Валидация (`@Valid`, собственные валидаторы)
  - Санитизация (escape, encode, `HtmlUtils.htmlEscape`)
  - Ограничение частоты (`@RateLimiter`, собственные фильтры)
  - Аудит-логирование (фиксация событий безопасности)
- `IDS_path = уникальные_категории_защиты / 6`
- `IDS_system = min(IDS_path)` по всем критическим путям.

Нормализация: инверсия `IDS = 1 - IDS_system`, чтобы 0 = безопасно (много слоёв), 1 = критично (нет слоёв). Исходное значение сохраняется в `raw_IDS`.

Реализация: `src/analyzer/metrics.py` (`metric_B1_IDS`), инверсия в `_normalize_metrics`.

---

### B2. Индекс близости к привилегиям (PPI)

Расстояние от неаутентифицированной точки входа до привилегированной операции в графе вызовов.

Алгоритм:
- Идентификация привилегированных операций: запись/удаление в БД, изменение прав, доступ к ПДн, финансовые транзакции.
- Идентификация публичных точек входа без авторизации.
- BFS по графу вызовов: минимальное количество переходов от публичного входа до привилегированной операции.
- `PPI = 1 / (min_distance + 1)` - чем короче путь, тем выше риск.

Диапазон: [0, 1], 0 = безопасно. Нормализация не требуется.

Реализация: `src/analyzer/metrics.py` (`metric_B2_PPI`).

---

### B3. Паритет защиты по путям (MPSP)

Одна и та же чувствительная операция часто доступна через несколько входных путей - REST API, Kafka, gRPC, job, internal call. Все ли пути защищены одинаково?

Алгоритм:
- Для каждого метода-приёмника (операция с БД, ФС, внешний API) находим всех вызывающих через обратный граф вызовов.
- Трассируем каждую цепочку вызовов до точки входа.
- Для каждого пути оцениваем меры безопасности (auth, authz, validation).
- `MPSP_operation = min(security_score_path) / max(security_score_path)`
  - 1.0 = все пути защищены одинаково (OK)
  - < 1.0 = есть путь слабее остальных (РИСК)
- `MPSP_system = min(MPSP_operation)` - самая слабая пара.

Нормализация: инверсия `MPSP = 1 - MPSP_system`, чтобы 0 = безопасно (полный паритет), 1 = критично (сильное расхождение). Исходное значение сохраняется в `raw_MPSP`.

Реализация: `src/analyzer/metrics.py` (`metric_B3_MPSP`), инверсия в `_normalize_metrics`.

---

### B4. Оценка безопасного отказа (FSS)

Что происходит, когда проверка безопасности падает с ошибкой? Пропускает или нет?

Алгоритм:
- Поиск всех catch-блоков, оборачивающих код, связанный с безопасностью
- Классификация поведения после catch:
  - Fail-closed (безопасно): re-throw, return error, deny access.
  - Fail-open (критично): continue execution, return true/success, пустой catch.
  - Ambiguous: log + continue - зависит от контекста.
- `FSS = (fail_closed_catches) / (all_security_catches)`
- Дополнительно: пустые catch-блоки (`catch (Exception e) {}`) в путях, связанных с безопасностью = отдельное критическое предупреждение.

Нормализация: инверсия `FSS_norm = 1 - FSS`, чтобы 0 = безопасно (все catch fail-closed), 1 = критично (все catch fail-open). Исходное значение сохраняется в `raw_FSS`.

Реализация: `src/analyzer/metrics.py` (`metric_B4_FSS`), инверсия в `_normalize_metrics`.

---

## Группа C: Потоки данных и утечки

> Куда текут данные? Куда утекают секреты? Что видит атакующий через ошибки?

---

### C1. Сложность пути заражённых данных (TPC)

Насколько глубоко данные уходят без валидации.

Алгоритм:
- Статический анализ графа вызовов от контроллера до приёмника-методов.
- Подсчёт максимального количества последовательных вызовов без валидации/санитизации на любом пути от входа до приёмника.
- `TPC = max_consecutive_unsafe_hops`

Нормализация: `TPC_norm = min(1, TPC / 10)`. Линейный cap при 10 хопах: 10 и более последовательных вызовов без очистки = максимальный риск. Исходное значение сохраняется в `raw_TPC`.

Реализация: `src/analyzer/metrics.py` (`metric_C1_TPC`), нормализация в `_normalize_metrics`.

---

### C2. Индекс прозрачности ошибок (ETI)

Куда уходит ошибка?

Алгоритм:
- AST-анализ всех catch-блоков / обработчиков ошибок.
- Трассировка: куда уходит exception?
  - `log only` → OK
  - `response body / HTTP response` → УТЕЧКА
  - `swallowed` (поглощён - пустой catch) → РИСК
- Паттерны утечки: `e.getMessage()` → response, конкатенация имён таблиц/путей в ответе, `printStackTrace()`.
- `ETI = (catch-блоки с утечкой) / (общее количество catch-блоков)`

Диапазон: [0, 1], 0 = безопасно. Нормализация не требуется.

Реализация: `src/analyzer/metrics.py` (`metric_C2_ETI`).

---

### C3. Анализ потоков секретов (SFA)

Уходят ли секреты в логи или ответы?

Алгоритм:
- Идентификация источников: переменные `password/token/secret/apiKey/creditCard`.
- Поиск строк, где слова-секреты совстречаются с паттернами логирования или сериализации.
- `SFA = (строки с утечкой) / (все строки с упоминанием секретов)`

Диапазон: [0, 1], 0 = безопасно. Нормализация не требуется.

Реализация: `src/analyzer/metrics.py` (`metric_C3_SFA`).

---

## Группа D: Архитектурная устойчивость

> Насколько код готов к быстрому и безопасному изменению при инцидентах?

---
### D1. Дрейф атак на стыках технологий (PAD)

Риск от смешения языков, спецификаций и сред выполнения.

Алгоритм:
- Подсчёт технологических границ по расширениям файлов: Java, Kotlin, JS, TS, Python, Go, Rust, C#.
- `PAD = max(0, count(languages) - 1)`

Нормализация: `PAD_norm = min(1, PAD / 4)`. Четыре и более технологических границы = максимальный риск. Исходное значение сохраняется в `raw_PAD`.

Реализация: `src/analyzer/metrics.py` (`metric_D1_PAD`), нормализация в `_normalize_metrics`. В текущей версии весовой коэффициент разрыва политики не реализован, используется чистый подсчёт границ.

---

### D2. Глубина распространения цепочки доверия (TCPD)

В микросервисах аутентификация проверяется на входе, а дальше - сервисы доверяют друг другу. Через сколько переходов безопасность путешествует без перепроверки?

Алгоритм:
- Для каждого пути от входной точки с auth до приёмника: сколько хопов после последней проверки auth/authz.
- `TCPD = max(hops_after_last_auth)` по всем путям.

Нормализация: `TCPD_norm = min(1, TCPD / 10)`. Линейный cap при 10 хопах. Исходное значение сохраняется в `raw_TCPD`.

Реализация: `src/analyzer/metrics.py` (`metric_D2_TCPD`), нормализация в `_normalize_metrics`.

---

## Группа E: Рассинхрон и расхождение

---

### E1. Риск зависимостей (OSDR)

Метрика оценивает риск, исходящий от набора объявленных зависимостей проекта. В отличие от инструментов SCA, которые проверяют наличие конкретных CVE, OSDR анализирует структуру зависимостей: долю «прочих» (не базовых и не внутренних) библиотек и наличие самописной криптографии.

Алгоритм:
- Парсит все `pom.xml` и `build.gradle` / `build.gradle.kts` в дереве репозитория (без запуска Maven/Gradle, без JVM, без сети).
- Определяет `groupId` проекта из корневого манифеста для выявления внутренних библиотек.
- Классифицирует каждую зависимость: BASELINE (Spring, Jackson, JUnit и т.д., вес 0), INTERNAL (самописные, вес 0), SECURITY_SELF (самописная криптография, вес 3), RISKY_SECURITY (сторонние security-библиотеки вне базового набора, вес 2), OTHER (всё остальное, вес 1).
- `OSDR = min(1.0, (count_other * 1.0 + count_security_self * 3.0 + count_risky_security * 2.0) / 50)`.

Диапазон: [0, 1]. 0 = безопасно. Нормализация не требуется. Работает в любом режиме (fast и full).

Реализация: `src/analyzer/metrics.py` (`metric_E1_OSDR`). Вес в агрегированном скоре: 0.06.

---

## Группа F: Предсказание и прогноз

> Не есть ли проблема сейчас, а что будет, когда проблема возникнет.

---

### F1. Предиктор сложности исправления уязвимости (VFCP)

Эта метрика агрегирует характеристики кода (сложность, связность, покрытие тестами, дубли, абстракции) в единый предиктор.

Алгоритм:
- Для каждого класса/модуля:
  - `coupling` = efferent coupling (исходящие зависимости), нормализация: `min(1, avg_out_degree / 20)`
  - `complexity` = средняя когнитивная сложность методов, нормализация: `min(1, avg / 30)`
  - `test_coverage` = статическая оценка покрытия тестами (0..1): доля production-классов, чьё имя встречается в исходниках тестов (эвристика по идентификаторам, без запуска тестов)
  - `duplicate_factor` = статическая оценка логических дублей (0..1): доля "дублированных" токенов в методах, где дубли определяются по хешу нормализованного тела метода (комментарии/литералы убираются, идентификаторы схлопываются); тесты и слишком маленькие методы игнорируются
  - `abstraction_level` = `1 - concrete_ratio`
 - `VFCP = 0.25 * coupling + 0.25 * complexity + 0.20 * (1 - test_coverage) + 0.15 * duplicate_factor + 0.15 * abstraction_level`

Диапазон: [0, 1], 0 = безопасно. Нормализация не требуется.

Реализация: `src/analyzer/metrics.py` (`metric_F1_VFCP`).

---

### F2. Вероятность регрессии безопасности (SRP)

Мутационное тестирование, только в контексте КБ.

Алгоритм:
- Выделяем конструкции, связанные с безопасностью через AST:
  - Проверки авторизации (`@PreAuthorize`, `@Secured`, `@RolesAllowed`)
  - Валидация (`@Valid`, собственные валидаторы)
  - Санитизация (escape, encode, sanitize)
- Для каждой конструкции: упоминается ли имя класса-носителя в тестовых файлах.
- `SRP = (конструкции безопасности без тестового покрытия) / (все конструкции безопасности)`

Диапазон: [0, 1], 0 = безопасно. Нормализация не требуется.

Реализация: `src/analyzer/metrics.py` (`metric_F2_SRP`). Проверка покрытия эвристическая: конструкция считается покрытой, если имя класса встречается в исходниках тестов.

---

## Мета-уровень: Композитная модель

---

### M1. Граф топологии безопасности - автоматическая модель угроз из кода

Представление кодовой базы как графа безопасности с метриками на каждом узле. Экспортирует топологию (узлы, рёбра, точки входа, приёмники) для визуализации. Нормализации не подлежит: информационная метрика.

Реализация: `src/analyzer/metrics.py` (`metric_M1_topology`). Экспорт ограничен 5000 узлов и 20000 рёбер.

---

## Агрегированный скор

Взвешенное среднее нормализованных значений всех метрик (кроме M1), приведённое к диапазону [0, 1], где 0 = безопасно, 1 = критично. Если метрика недоступна (например, граф вызовов не построен для проекта без Java-исходников или отсутствуют манифесты сборки для E1), она исключается из расчёта, а веса перенормируются на оставшиеся.

Веса по группам:

| Группа | Метрика | Вес | Обоснование |
|--------|---------|-----|-------------|
| A (поверхность атаки) | A1 | 0.08 | Масштаб поверхности атаки |
| | A2 | 0.07 | Сложность вблизи входа |
| | A3 | 0.07 | Доверчивость к входным данным |
| B (защита в глубину) | B1 | 0.10 | Отсутствие эшелонов -- сильнейший предиктор инцидентов |
| | B2 | 0.10 | Прямой путь к привилегированным операциям |
| | B3 | 0.05 | Расхождение защиты по путям |
| | B4 | 0.05 | Поведение при сбое проверки |
| C (потоки данных) | C1 | 0.08 | Глубина без очистки |
| | C2 | 0.06 | Утечка через ошибки |
| | C3 | 0.08 | Утечка секретов |
| D (архитектура) | D1 | 0.04 | Технологические границы |
| | D2 | 0.06 | Цепочка доверия |
| E (зависимости) | E1 | 0.06 | Структура и классификация зависимостей |
| F (предсказание) | F1 | 0.05 | Сложность исправления |
| | F2 | 0.05 | Регрессия безопасности |
| | **Сумма** | **1.00** | |

Реализация: `src/analyzer/metrics.py` (`_compute_aggregate`). Результат помещается в секцию `aggregate` с полями `score`, `components` (нормализованные значения каждой метрики), `available` (сколько метрик участвовало) и `notes`.

---

## Система дефектов (findings)

Каждая метрика, помимо числового значения, формирует список конкретных дефектов, обнаруженных в кодовой базе. Дефект содержит следующие поля:

- `metric` — идентификатор метрики (A1, B4, E1 и т.д.).
- `severity` — уровень серьёзности: `critical`, `high`, `medium`, `low`.
- `file` — относительный путь к файлу.
- `line` — номер строки (если определим).
- `method` — идентификатор метода.
- `what` — краткое описание проблемы.
- `why` — объяснение, почему это опасно.
- `fix` — рекомендация по устранению.

Примеры генерируемых дефектов: «Endpoint без аутентификации» (A1), «Пустой catch-блок» (B4), «Самописная security/crypto библиотека» (E1), «Конструкция безопасности не покрыта тестами» (F2). Полный перечень типов дефектов определяется логикой каждой метрики.

Дефекты сортируются по серьёзности и отображаются в интерактивном HTML-отчёте на вкладке «Дефекты» с фильтрацией по группе метрик и уровню серьёзности. Это даёт команде не только числовой индекс, но и конкретный перечень мест в коде, требующих внимания, с объяснением природы проблемы и способа её устранения.

Реализация: каждая функция `metric_*` в `src/analyzer/metrics.py` возвращает ключ `findings` со списком дефектов. Сбор и сортировка — `src/analyzer/render_report.py` (`_build_graph_data`).
